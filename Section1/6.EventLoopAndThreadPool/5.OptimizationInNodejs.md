### Optimizing Node.js for High Concurrency 🚀
- Node.js is designed for high concurrency with non-blocking I/O and an event-driven architecture, but it can still struggle with CPU-intensive tasks or high request loads. Here’s how to optimize Node.js performance effectively.


1. ## Use Worker Threads for CPU-Intensive Tasks
- The Node.js event loop is single-threaded, so CPU-heavy operations (e.g., hashing, image processing) block the main thread.
- ✅ Solution: Use worker_threads to offload CPU-bound work to separate threads.
- Example: Offloading CPU Work with Worker Threads
```js
const { Worker } = require('worker_threads');

function runWorkerTask(workerData) {
    return new Promise((resolve, reject) => {
        const worker = new Worker('./worker-task.js', { workerData });
        worker.on('message', resolve);
        worker.on('error', reject);
        worker.on('exit', (code) => {
            if (code !== 0) reject(new Error(`Worker stopped with exit code ${code}`));
        });
    });
}

// Call worker thread
runWorkerTask(100000000).then(console.log).catch(console.error);
```
```js
const { parentPort, workerData } = require('worker_threads');

let sum = 0;
for (let i = 0; i < workerData; i++) {
    sum += i;
}
parentPort.postMessage(sum);

```
2. ## Increase Thread Pool Size for I/O-Intensive Apps
- By default, Node.js’ thread pool has 4 worker threads (libuv default). You can increase it for better performance with I/O-heavy workloads.
- How to Increase Thread Pool Size?
- Set the UV_THREADPOOL_SIZE environment variable (max: CPU core count).
```
export UV_THREADPOOL_SIZE=8  # Linux/macOS
set UV_THREADPOOL_SIZE=8      # Windows

```
## ✅ Best for:
- File system operations (fs.readFile, fs.writeFile)
- Database queries (MongoDB, PostgreSQL, MySQL)
- Compression (zlib.gzip())
- Cryptographic operations (crypto.pbkdf2())

3. ## Use Cluster Mode to Utilize Multiple CPU Cores
- By default, Node.js runs on a single CPU core. The cluster module allows creating multiple processes to handle requests efficiently.
- Example: Load Balancing Using Clustering
```js
const cluster = require('cluster');
const http = require('http');
const os = require('os');

if (cluster.isMaster) {
    const numCPUs = os.cpus().length;
    console.log(`Master process running on PID: ${process.pid}`);
    
    // Fork workers (1 per CPU core)
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }

    // Restart worker if it crashes
    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} died, restarting...`);
        cluster.fork();
    });

} else {
    // Each worker runs a server
    http.createServer((req, res) => {
        res.writeHead(200);
        res.end(`Handled by worker ${process.pid}\n`);
    }).listen(8000);

    console.log(`Worker ${process.pid} started`);
}
```
## ✅ Benefit:
- Distributes load across all CPU cores.
- Prevents a single process from becoming a bottleneck.


4. ## Use Load Balancing with PM2
- PM2 is a production-ready process manager for Node.js apps. It supports auto-scaling, log management, and monitoring.
## ✅ PM2 will:
- Automatically scale across CPU cores.
- Restart crashed processes.
- Monitor resource usage (pm2 monit).

5. ## Use Caching to Reduce Load
- Reducing redundant computations with caching improves performance significantly.
- 1️⃣ In-Memory Caching (Fastest, but Limited by RAM)
- Use lru-cache for short-lived cache storage.
const LRU = require('lru-cache');
const cache = new LRU({ max: 500 });
```js
function getCachedData(key) {
    if (cache.has(key)) return cache.get(key);
    const data = expensiveCalculation();
    cache.set(key, data);
    return data;
}
```
- ✅ Best for: Repeated computations, API responses, authentication tokens.
- 2️⃣ Redis Caching (Persistent, Scalable)
Use Redis for distributed caching (works across multiple servers).

6. ## Optimize Database Queries
- 1️⃣ Use Connection Pooling
- Avoid creating new connections for every request. Use a pool instead.
```js
const { Pool } = require('pg');
const pool = new Pool({ max: 10 });

pool.query('SELECT * FROM users', (err, res) => {
    if (err) throw err;
    console.log(res.rows);
});
2️⃣ Use Indexing for Faster Queries
```
- Always index columns used in WHERE or JOIN conditions.

7. ## Use Streams for Large Data Processing
- Instead of loading large files fully into memory, use streams.
- Example: Streaming a Large File

```js
const fs = require('fs');

fs.createReadStream('bigfile.txt')
  .pipe(fs.createWriteStream('output.txt'))
  .on('finish', () => console.log('File copied!'));
```
- ✅ Uses constant memory, no matter how large the file is.
